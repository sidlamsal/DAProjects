{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0496e81",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d044af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import warnings\n",
    "import gower\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras import backend as K\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred): # TPR\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # TP\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1))) # P\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # TP\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1))) # TP + FP\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "    \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1_m2(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred)\n",
    "    #precision = precision_m(y_true, y_pred)\n",
    "    #recall = recall_m(y_true, y_pred)\n",
    "    #return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def TP(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # TP\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    n_pos = K.sum(y_pos)\n",
    "    y_neg = 1 - y_pos\n",
    "    n_neg = K.sum(y_neg)\n",
    "    n = n_pos + n_neg\n",
    "    return tp/n\n",
    "\n",
    "def TN(y_true, y_pred):\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    n_pos = K.sum(y_pos)\n",
    "    y_neg = 1 - y_pos\n",
    "    n_neg = K.sum(y_neg)\n",
    "    n = n_pos + n_neg\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    tn = K.sum(K.round(K.clip(y_neg * y_pred_neg, 0, 1))) # TN\n",
    "    return tn/n\n",
    "\n",
    "def FP(y_true, y_pred):\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    n_pos = K.sum(y_pos)\n",
    "    y_neg = 1 - y_pos\n",
    "    n_neg = K.sum(y_neg)\n",
    "    n = n_pos + n_neg\n",
    "    tn = K.sum(K.round(K.clip(y_neg * y_pred, 0, 1))) # FP\n",
    "    return tn/n\n",
    "\n",
    "def FN(y_true, y_pred):\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    n_pos = K.sum(y_pos)\n",
    "    y_neg = 1 - y_pos\n",
    "    n_neg = K.sum(y_neg)\n",
    "    n = n_pos + n_neg\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    tn = K.sum(K.round(K.clip(y_true * y_pred_neg, 0, 1))) # FN\n",
    "    return tn/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy after each batch\n",
    "class BCP(tf.keras.callbacks.Callback):\n",
    "    batch_accuracy = [] # accuracy at given batch\n",
    "    batch_f1 = [] # f1 at given batch\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BCP,self).__init__() \n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        BCP.batch_accuracy.append(logs.get('accuracy'))\n",
    "        BCP.batch_f1.append(logs.get('f1_m'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy after each batch\n",
    "class BCP2(tf.keras.callbacks.Callback):\n",
    "    batch_accuracy = [] # accuracy at given batch\n",
    "    batch_f1 = [] # f1 at given batch\n",
    "    batch_f1_val = [] # f1 of validation at given batch\n",
    "    \n",
    "    def __init__(self, val_data):\n",
    "        super(BCP,self).__init__() \n",
    "        self.validation_data = val_data\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        x_val = self.validation_data[0]\n",
    "        y_val_true = self.validation_data[1]\n",
    "        y_val_pred = self.model.predict(x_val, verbose=0)\n",
    "        \n",
    "        print(vars(self))\n",
    "        print(vars(batch))\n",
    "        print(vars(logs))\n",
    "        \n",
    "        y_val_class = [0 if val < .5 else 1 for val in y_val_pred]\n",
    "        batchF1 = f1_m2(y_val_true, y_val_class)\n",
    "        \n",
    "        BCP.batch_f1_val.append(batchF1)\n",
    "        BCP.batch_accuracy.append(logs.get('accuracy'))\n",
    "        BCP.batch_f1.append(logs.get('f1_m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1538a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalNN(thresh, pred, ytest):\n",
    "    plotROC(pred, ytest)\n",
    "    classPred = [0 if val < thresh else 1 for val in pred]\n",
    "    evaluate(ytest, classPred, thresh)\n",
    "\n",
    "def thresh(pred, ytest):\n",
    "    bestacc = 0\n",
    "    besttp = 0\n",
    "    bestf1 = 0\n",
    "    bestthresh = 0\n",
    "    accList = []\n",
    "    tpList = []\n",
    "    f1list = []\n",
    "    threshlist = []\n",
    "    for i in range(1,100):\n",
    "        classPred = [0 if val < (i/100) else 1 for val in pred]\n",
    "        accuracy = accuracy_score(ytest, classPred)\n",
    "        tpr = recall_score(ytest, classPred)\n",
    "        f1 = f1_score(ytest, classPred)\n",
    "        accList.append(accuracy)\n",
    "        tpList.append(tpr)\n",
    "        f1list.append(f1)\n",
    "        threshlist.append(i)\n",
    "        if (f1>bestf1):\n",
    "            bestacc= accuracy\n",
    "            besttp = tpr\n",
    "            bestf1 = f1\n",
    "            bestthresh=i\n",
    "            \n",
    "    plt.plot(threshlist, accList, 'b', label='Accuracy')\n",
    "    plt.plot(threshlist, tpList, 'r', label='Recall')\n",
    "    plt.plot(threshlist, f1list, 'g', label='F1 score')\n",
    "    plt.axvline(x = bestthresh, color = 'k', label = 'Best threshold')\n",
    "    plt.title('Threshold Graph')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return (bestthresh/100)\n",
    "\n",
    "def plotNN(history):\n",
    "    # Extract accuracy and TPR values from the training history\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    f1 = history.history['f1_m']\n",
    "    val_f1 = history.history['val_f1_m']\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "    # Plot the accuracy values\n",
    "    plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "    \n",
    "    # Plot the recall values\n",
    "    plt.plot(epochs, f1, 'k', label='Training f1')\n",
    "    plt.plot(epochs, val_f1, 'c', label='Validation f1')\n",
    "\n",
    "    plt.title('Training and Validation Metrics')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def NN(df, xtest, ytest):\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    BCP.batch_accuracy.clear()\n",
    "    BCP.batch_f1.clear()\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "    \n",
    "    history = model.fit(xtrain, ytrain, epochs=200, batch_size=32, shuffle=False, \n",
    "                        validation_data=val_data, callbacks = [BCP()], verbose=0)\n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_f1)), BCP.batch_f1, 'r', label='F1')\n",
    "    plt.title('Batch F1 Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plotNN(history)\n",
    "    \n",
    "    print(\"########################   TRAIN   ########################\")\n",
    "    pred = model.predict(xtrain)\n",
    "    threshold = thresh(pred, ytrain)\n",
    "    evalNN(threshold, pred, ytrain)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n\\n########################   TEST   ########################\")\n",
    "    pred = model.predict(xtest)\n",
    "    evalNN(threshold, pred, ytest)\n",
    "    \n",
    "def NNSH(df, xtest, ytest):\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    BCP.batch_accuracy.clear()\n",
    "    BCP.batch_f1.clear()\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "    \n",
    "    history = model.fit(xtrain, ytrain, epochs=200, batch_size=32, shuffle=True, \n",
    "                        validation_data=val_data, callbacks = [BCP()], verbose=0)\n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_f1)), BCP.batch_f1, 'r', label='F1')\n",
    "    plt.title('Batch F1 Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plotNN(history)\n",
    "    print(\"########################   TRAIN   ########################\")\n",
    "    pred = model.predict(xtrain)\n",
    "    threshold = thresh(pred, ytrain)\n",
    "    evalNN(threshold, pred, ytrain)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n\\n########################   TEST   ########################\")\n",
    "    pred = model.predict(xtest)\n",
    "    evalNN(threshold, pred, ytest)\n",
    "    \n",
    "def plotROC(prob, ytest):\n",
    "    fpr, tpr, _ = metrics.roc_curve(ytest,  prob)\n",
    "    auc = metrics.roc_auc_score(ytest, prob)\n",
    "    #create ROC curve\n",
    "    plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "    plt.title('ROC and AUC')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "def findClosest(num):\n",
    "    i = (notSBD['Prob'] - num).abs().idxmin()\n",
    "    row = notSBD.loc[i]\n",
    "    notSBD.drop(i, inplace=True)\n",
    "    return row\n",
    "\n",
    "def evaluate(acc, pred, bestthresh):\n",
    "    cm = confusion_matrix(acc, pred)\n",
    "    bestacc = accuracy_score(acc, pred)\n",
    "    besttp = recall_score(acc, pred)\n",
    "    bestf1 = f1_score(acc, pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Best Threshold:\", bestthresh)\n",
    "    print(\"Accuracy:\", bestacc)\n",
    "    print(\"Recall:\", besttp)\n",
    "    print(\"F1:\", bestf1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def dist(df):\n",
    "    yes = len(df[df[\"Churn_Yes\"] == 1])\n",
    "    no = len(df[df[\"Churn_Yes\"] == 0])\n",
    "    print(\"Churn Yes:\", yes)\n",
    "    print(\"Churn No:\", no)\n",
    "    return (yes, no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d94ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "churn = pd.read_csv(r\"C:\\Users\\21sla\\OneDrive - Dickinson College\\Data300\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "print(\"Before:\", len(churn))\n",
    "churn = churn.dropna(how= 'any', axis=0)\n",
    "print(\"After:\", len(churn))\n",
    "#churn.head(5)\n",
    "churn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d62bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop ID\n",
    "clean = churn.drop(\"customerID\", axis=1)\n",
    "\n",
    "#Remove missing values\n",
    "clean.replace(' ', np.nan, inplace=True)\n",
    "print(\"Before:\", len(clean))\n",
    "clean = clean.dropna(how= 'any', axis=0)\n",
    "print(\"After:\", len(clean))\n",
    "\n",
    "#set data types\n",
    "clean[\"TotalCharges\"] = clean[\"TotalCharges\"].astype(float)\n",
    "clean[\"SeniorCitizen\"] = clean[\"SeniorCitizen\"].astype(object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7e944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make dummies\n",
    "dummies = pd.get_dummies(clean, drop_first= True)\n",
    "clean = dummies\n",
    "clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c3da8",
   "metadata": {},
   "source": [
    "# Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87e160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = clean.drop('Churn_Yes', axis=1)\n",
    "y = clean['Churn_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c76fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482193b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c510133",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc8c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training \n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d278e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Getting probabilities\n",
    "yprob = model.predict_proba(xtest)\n",
    "threshold = thresh(yprob[:, 1], ytest)\n",
    "#threshold = 0.5\n",
    "ypred = (yprob[:, 1] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f61737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Log results\n",
    "evaluate(ytest,ypred, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cda474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe796a03",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518a30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fittedProb = model.predict_proba(xtrain)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf4875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fittedClass = (fittedProb > threshold).astype(int)\n",
    "probdf = xtrain.copy()\n",
    "probdf[\"Churn_Yes\"] = ytrain\n",
    "probdf[\"Prob\"] = fittedProb\n",
    "probdf[\"Class\"] = fittedClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82e707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(ytrain,fittedClass, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1edee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "misses = probdf[probdf[\"Churn_Yes\"] != probdf[\"Class\"]]\n",
    "len(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929606ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd3830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Simple oversample###\n",
    "\n",
    "class1 = probdf[probdf[\"Churn_Yes\"] == 1]\n",
    "distribution = dist(probdf)\n",
    "\n",
    "oversample = class1.sample(n=(distribution[1]-distribution[0]), replace = True)\n",
    "\n",
    "overDf = pd.concat([probdf, oversample], ignore_index=True)\n",
    "\n",
    "dist(overDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a103a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Oversample misses###\n",
    "\n",
    "missDf = pd.concat([probdf, misses], ignore_index=True)\n",
    "len(missDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5bf2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Hybrid###\n",
    "\n",
    "missedClass1 = misses[misses[\"Churn_Yes\"] == 1]\n",
    "overmiss = missedClass1.sample(n=(distribution[1]-distribution[0]), replace = True)\n",
    "\n",
    "overMissDf = pd.concat([probdf, overmiss], ignore_index=True)\n",
    "dist(overMissDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da1d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d00bf4c",
   "metadata": {},
   "source": [
    "# Similar Probability, Different Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990479d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69448026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class1 = probdf[probdf[\"Churn_Yes\"] == 1].sort_values(by=\"Prob\")\n",
    "class0 = probdf[probdf[\"Churn_Yes\"] == 0].sort_values(by=\"Prob\")\n",
    "\n",
    "#Similar but different\n",
    "SBD = pd.DataFrame()\n",
    "notSBD = class0.copy()\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for i in range(len(class1)):\n",
    "        #print(len(SBD))\n",
    "        row = class1.iloc[i]\n",
    "        SBD = SBD.append(row)\n",
    "        row2 = findClosest(row[\"Prob\"])\n",
    "        SBD = SBD.append(row2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db20d23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(notSBD))\n",
    "print(len(class0))\n",
    "print(len(probdf))\n",
    "print(len(SBD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543324fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SBD[[\"Churn_Yes\", \"Prob\", \"Class\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44a1e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22934ae9",
   "metadata": {},
   "source": [
    "# Hard/Easy To Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24aca37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Min and max prob\n",
    "print(\"Min\", max(float(class0[\"Prob\"].head(1)), float(class1[\"Prob\"].head(1))))\n",
    "print(\"Max\", min(float(class0[\"Prob\"].tail(1)), float(class1[\"Prob\"].tail(1))))\n",
    "class1 = probdf[probdf[\"Churn_Yes\"] == 1].sort_values(by=\"Prob\")\n",
    "class0 = probdf[probdf[\"Churn_Yes\"] == 0].sort_values(by=\"Prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf368f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardToPredict(std, threshold):\n",
    "    \n",
    "    upperlimit = threshold + std\n",
    "    lowerlimit = threshold - std\n",
    "    \n",
    "    print(\"Upperlimit:\", upperlimit, \"Lowerlimit:\", lowerlimit)\n",
    "    \n",
    "    C0HP = class0[(class0[\"Prob\"]>upperlimit)].sort_values(by=\"Prob\", ascending = False)\n",
    "    notC0Hp = class0[(class0[\"Prob\"]<=upperlimit)]\n",
    "\n",
    "    C1LP = class1[(class1[\"Prob\"]<lowerlimit)].sort_values(by=\"Prob\")\n",
    "    notC1LP = class1[(class1[\"Prob\"]>=lowerlimit)]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "        notHTP = pd.DataFrame().append(notC0Hp).append(notC1LP)\n",
    "        HTP = pd.DataFrame()\n",
    "        \n",
    "        alternate = min(len(C0HP), len(C1LP))\n",
    "        for i in range (0, alternate):\n",
    "            HTP = HTP.append(C0HP.iloc[i]).append(C1LP.iloc[i])\n",
    "            #print(len(orderedHTP))\n",
    "\n",
    "        if (alternate == len(C0HP)):\n",
    "            HTP = HTP.append(C1LP.iloc[(len(C0HP)):(len(C1LP))])\n",
    "\n",
    "        else:\n",
    "            HTP = HTP.append(C0HP.iloc[(len(C1LP)):(len(C0HP))])\n",
    "    \n",
    "    print(\"HTP:\", len(HTP))\n",
    "    print(\"notHTP:\", len(notHTP))\n",
    "    \n",
    "    return (HTP, notHTP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b6188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stdProb = .5 * probdf[\"Prob\"].std()\n",
    "\n",
    "fullHTP = hardToPredict(stdProb, threshold)\n",
    "\n",
    "notHTP = fullHTP[1]\n",
    "HTP = fullHTP[0]\n",
    "\n",
    "print(\"HTP:\", len(HTP))\n",
    "print(\"notHTP:\", len(notHTP))\n",
    "\n",
    "HTP[[\"Churn_Yes\", \"Prob\", \"Class\"]].head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ef0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d63211",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperlimit = threshold + stdProb\n",
    "lowerlimit = threshold - stdProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ec7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = probdf[probdf['Prob'].between(lowerlimit, upperlimit)]\n",
    "\n",
    "notsave = probdf.copy()\n",
    "notsave = notsave.drop(save.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a504206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(save))\n",
    "print(len(notsave))\n",
    "len(probdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce546a8",
   "metadata": {},
   "source": [
    "# Weighted Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48511669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75543106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def weightedBatches(higherWeightdf, lowerWeightdf, weightMultiplier, unitsPerBatch, v=False):\n",
    "    numBatches = math.floor((len(higherWeightdf) + len(lowerWeightdf))/unitsPerBatch)\n",
    "    \n",
    "    high = higherWeightdf.copy()\n",
    "    low = lowerWeightdf.copy()\n",
    "    \n",
    "    low[\"weight\"] = 1\n",
    "    high[\"weight\"] = weightMultiplier\n",
    "    \n",
    "    joint = pd.concat([low, high])\n",
    "    weighted = pd.DataFrame()\n",
    "    \n",
    "    numWeighted = []\n",
    "    \n",
    "    for i in range(numBatches):\n",
    "        sample = joint.sample(n = unitsPerBatch, replace=False, weights='weight')\n",
    "        joint = joint.drop(sample.index)\n",
    "        \n",
    "        numWeighted.append(len(sample[sample[\"weight\"] == weightMultiplier]))\n",
    "        weighted = pd.concat([weighted, sample])\n",
    "    \n",
    "    weighted = pd.concat([weighted, joint])\n",
    "    \n",
    "    mp = math.floor(len(numWeighted)/2)\n",
    "    \n",
    "    if (v):\n",
    "        print(\"Weighted units per batch in first half:\", sum(numWeighted[0:mp])/mp)\n",
    "\n",
    "        print(\"Weighted units per batch in second half:\", sum(numWeighted[mp:])/(len(numWeighted)-mp))\n",
    "    \n",
    "    return weighted.drop([\"weight\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd69d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weightedHTP = weightedBatches(HTP, notHTP, 3, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88c0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weightedHTP.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89745a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0aec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2fef649",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48497c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(model, xtest, ytest):\n",
    "    test = xtest.copy()\n",
    "    test[\"Churn_Yes\"] = ytest\n",
    "\n",
    "    BSF1 = []\n",
    "\n",
    "    for i in range(30):\n",
    "        bootstrapTest = test.iloc[np.random.choice(len(test), size=len(test), replace=True)]\n",
    "        xtest = bootstrapTest.drop('Churn_Yes', axis=1)\n",
    "        ytest = bootstrapTest['Churn_Yes']\n",
    "\n",
    "        pred = model.predict(xtest, verbose=0)\n",
    "        bestThresh = thresh2(pred, ytest)\n",
    "        classPred = [0 if val < bestThresh else 1 for val in pred]\n",
    "        f1 = f1_score(ytest, classPred)\n",
    "        BSF1.append(f1)\n",
    "    \n",
    "    return sum(BSF1)/len(BSF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh2(pred, ytest):\n",
    "    bestf1 = 0\n",
    "    bestthresh = 0\n",
    "    f1list = []\n",
    "    threshlist = []\n",
    "    for i in range(1,100):\n",
    "        classPred = [0 if val < (i/100) else 1 for val in pred]\n",
    "        f1 = f1_score(ytest, classPred)\n",
    "        f1list.append(f1)\n",
    "        threshlist.append(i)\n",
    "        if (f1>bestf1):\n",
    "            bestf1 = f1\n",
    "            bestthresh=(i/100)\n",
    "\n",
    "    return bestthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82cd020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41ba91d",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d1a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18742959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNSH(probdf.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220aea6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Oversample\n",
    "NNSH(overDf.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b67e17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Oversample Misses\n",
    "NN(missDf.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4237331",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hybrid oversample\n",
    "NNSH(overMissDf.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa29b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes = pd.concat([SBD, notSBD]).drop([\"Class\", \"Prob\"], axis=1)\n",
    "#SBD with other\n",
    "NN(concatRes, xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61021fff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes2 = pd.concat([HTP, notHTP]).drop([\"Class\", \"Prob\"], axis=1)\n",
    "#HTP with other\n",
    "NN(concatRes2, xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d92cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes3 = pd.concat([save, notsave]).drop([\"Class\", \"Prob\"], axis=1)\n",
    "#HTP with other\n",
    "NN(concatRes3, xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ed14a",
   "metadata": {},
   "source": [
    "# Weighted Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea0271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WNN(high, low, xtest, ytest):\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', f1_m])\n",
    "\n",
    "    BCP.batch_accuracy.clear()\n",
    "    BCP.batch_f1.clear()\n",
    "\n",
    "    val_data = (xtest, ytest)\n",
    "\n",
    "    accuracy = []\n",
    "    val_accuracy = []\n",
    "    f1 = []\n",
    "    val_f1 = []\n",
    "    epochs = range(1, 201)\n",
    "    \n",
    "    for i in range(200):\n",
    "        df = weightedBatches(high, low, 5, 32)\n",
    "        #print(df.head(1))\n",
    "        xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "        ytrain = df[\"Churn_Yes\"]\n",
    "\n",
    "        history = model.fit(xtrain, ytrain, epochs=1, batch_size=32, shuffle=False, \n",
    "                            validation_data=val_data, callbacks = [BCP()], verbose=0)\n",
    "        accuracy.append(history.history['accuracy'])\n",
    "        val_accuracy.append(history.history['val_accuracy'])\n",
    "        f1.append(history.history['f1_m'])\n",
    "        val_f1.append(history.history['val_f1_m'])\n",
    "        \n",
    "    ###########\n",
    "    # Plot the accuracy values\n",
    "    plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "    \n",
    "    # Plot the recall values\n",
    "    plt.plot(epochs, f1, 'k', label='Training f1')\n",
    "    plt.plot(epochs, val_f1, 'c', label='Validation f1')\n",
    "\n",
    "    plt.title('Training and Validation Metrics')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    ###########\n",
    "\n",
    "\n",
    "    plt.plot(range(len(BCP.batch_f1)), BCP.batch_f1, 'r', label='F1')\n",
    "    plt.title('Batch F1 Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"########################   TRAIN   ########################\")\n",
    "    pred = model.predict(xtrain)\n",
    "    threshold = thresh(pred, ytrain)\n",
    "    evalNN(threshold, pred, ytrain)\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n########################   TEST   ########################\")\n",
    "    pred = model.predict(xtest)\n",
    "    evalNN(threshold, pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b58c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WNN(HTP.drop([\"Class\", \"Prob\"], axis=1), notHTP.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3db1ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WNN(save.drop([\"Class\", \"Prob\"], axis=1), notsave.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8e2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9104f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057532e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f43bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5630b27",
   "metadata": {},
   "source": [
    "# Easy First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21c468",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes = pd.concat([notSBD, SBD]).drop_duplicates()\n",
    "#SBD with other\n",
    "NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66421a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes = pd.concat([notHTP, HTP]).drop_duplicates()\n",
    "#HTP with other\n",
    "NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37a88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11c66e0c",
   "metadata": {},
   "source": [
    "# Add more Hard to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899ab3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concatRes = pd.concat([HTP, HTP, notHTP])\n",
    "NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e63b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatRes = pd.concat([HTP, HTP, HTP, notHTP])\n",
    "NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatRes = pd.concat([HTP, HTP, HTP, HTP, notHTP])\n",
    "NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede6285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist(misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa133c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a25dfc7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3858340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cca001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "data = probdf.drop([\"Churn_Yes\",\"Class\", \"Prob\"], axis=1)\n",
    "# Specify the column indices of numerical variables\n",
    "num_cols = [0, 1, 2]\n",
    "\n",
    "# Specify the column indices of categorical variables\n",
    "cat_cols = list(range(3, 30))\n",
    "\n",
    "# Specify the number of clusters\n",
    "n_clusters = 3\n",
    "\n",
    "# Initialize and fit the K-Prototypes model\n",
    "kproto = KPrototypes(n_clusters=n_clusters, init='Cao', verbose=False)\n",
    "clusters = kproto.fit_predict(data.values, categorical=cat_cols)\n",
    "\n",
    "# Add the cluster labels to the original dataset\n",
    "data['Cluster'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2408e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "plt.scatter(data['tenure'], data['MonthlyCharges'], c=data['Cluster'], cmap='viridis')\n",
    "plt.xlabel('tenure')\n",
    "plt.ylabel('MonthlyCharges')\n",
    "plt.title('K-Prototypes Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccba4ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "plt.scatter(class0['tenure'], class0['MonthlyCharges'], c=\"g\", label=\"0\")\n",
    "plt.scatter(class1['tenure'], class1['MonthlyCharges'], c=\"b\", label=\"1\")\n",
    "plt.scatter(misses['tenure'], misses['MonthlyCharges'], c=\"r\", marker = \"x\", label=\"Misses\")\n",
    "plt.xlabel('tenure')\n",
    "plt.ylabel('MonthlyCharges')\n",
    "plt.title('Misses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987498c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc(df, var):\n",
    "    class0 = df[df[\"Churn_Yes\"] == 0]\n",
    "    class1 = df[df[\"Churn_Yes\"] == 1]\n",
    "    \n",
    "    total = len(class0) + len(class1)\n",
    "    zero = len(class0)/total\n",
    "    one = len(class1)/total\n",
    "    \n",
    "    class0var0 = class0[class0[var] == 0]\n",
    "    class0var1 = class0[class0[var] == 1]\n",
    "    \n",
    "    class1var0 = class1[class1[var] == 0]\n",
    "    class1var1 = class1[class1[var] == 1]\n",
    "    \n",
    "    zeroZero = zero * len(class0var0)/len(class0)\n",
    "    zeroOne = zero *len(class0var1)/len(class0)\n",
    "    \n",
    "    oneZero = one * len(class1var0)/len(class1)\n",
    "    oneOne = one * len(class1var1)/len(class1)\n",
    "    \n",
    "    return([zeroZero, zeroOne, oneZero, oneOne])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21efe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "misses.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b30122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotpie(df, var):\n",
    "    labels = [\"00\", \"01\", \"10\", \"11\"]\n",
    "    sizes = perc(df, var)\n",
    "    print(sizes)\n",
    "    colors = ['red', 'green', 'cyan', 'magenta']\n",
    "\n",
    "    # Create the pie chart\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "    # Set aspect ratio to be equal so that pie is drawn as a circle\n",
    "    plt.axis('equal')\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(var)\n",
    "\n",
    "    # Display the chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37d176",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = misses.columns.tolist()\n",
    "\n",
    "for i in range(3, 30):\n",
    "    plotpie(probdf, columns[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be29ea",
   "metadata": {},
   "source": [
    "# RWS, Val Batch, Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ff57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(df, xtest, ytest):\n",
    "    \n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', f1_m, recall_m, precision_m])\n",
    "\n",
    "    \n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    BCP.batch_accuracy.clear()\n",
    "    BCP.batch_f1.clear()\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "    \n",
    "    print(\"Starting Model Training\")\n",
    "    history = model.fit(xtrain, ytrain, epochs=5, batch_size=50, shuffle=False, \n",
    "                        validation_data=val_data, callbacks = [BCP()], verbose=0)\n",
    "    print(\"Model Training Finished\")\n",
    "    \n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_accuracy)), BCP.batch_accuracy, 'b', label='Accuracy')\n",
    "    plt.title('Batch Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_f1_val)), BCP.batch_f1_val, 'r', label='Val F1')\n",
    "    plt.title('Batch Val F1 Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Training ROC:\")\n",
    "    pred = model.predict(xtrain)\n",
    "    #print(pred)\n",
    "    plotROC(pred, ytrain)\n",
    "    plotNN(history)\n",
    "    evalNN(model, xtest, ytest)\n",
    "    print(\"Bootstrap:\", bootstrap(model, xtest, ytest))\n",
    "    \n",
    "    return (BCP.batch_accuracy, BCP.batch_f1, BCP.batch_f1_val)\n",
    "    \n",
    "def NNSh(df, xtest, ytest):\n",
    "    \n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy' ,f1_m, recall_m, precision_m])\n",
    "    \n",
    "    \n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    BCP.batch_accuracy.clear()\n",
    "    BCP.batch_f1.clear()\n",
    "    BCP.batch_f1_val.clear()\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "    \n",
    "    print(\"Starting Model Training\")\n",
    "    history = model.fit(xtrain, ytrain, epochs=5, batch_size=50, shuffle=True, \n",
    "                        validation_data=val_data, callbacks = [BCP(val_data)], verbose=0)\n",
    "    print(\"Model Training Finished\")\n",
    "    \n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_accuracy)), BCP.batch_accuracy, 'b', label='Accuracy')\n",
    "    plt.title('Batch Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(len(BCP.batch_f1_val)), BCP.batch_f1_val, 'r', label='Val F1')\n",
    "    plt.title('Batch Val F1 Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Training ROC:\")\n",
    "    pred = model.predict(xtrain)\n",
    "    #print(pred)\n",
    "    plotROC(pred, ytrain)\n",
    "    plotNN(history)\n",
    "    evalNN(model, xtest, ytest)\n",
    "    print(\"Bootstrap:\", bootstrap(model, xtest, ytest))\n",
    "    \n",
    "    return (BCP.batch_accuracy, BCP.batch_f1, BCP.batch_f1_val)\n",
    "\n",
    "def plotBatch(stat, stat2, name):\n",
    "    plt.plot(range(len(stat)), stat, 'b', label='No Shuffel')\n",
    "    plt.plot(range(len(stat2)), stat2, 'r', label='Shuffel')\n",
    "    \n",
    "    plt.title(name + 'Batch Graph')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedHTP = weightedBatches(HTP, notHTP, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ed029",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedsave = weightedBatches(save, notsave, 3, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb0c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7ff5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normsh = NNSh(probdf.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normsh[0].copy()\n",
    "y = normsh[1].copy()\n",
    "z = normsh[2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c7e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weightedHTPData = NN(weightedHTP.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = weightedHTPData[0].copy()\n",
    "y1 = weightedHTPData[1].copy()\n",
    "z1 = weightedHTPData[2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c49a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weightedSaveData = NN(weightedsave.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = weightedSaveData[0].copy()\n",
    "y2 = weightedSaveData[1].copy()\n",
    "z2 = weightedSaveData[2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31dae1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatRes = pd.concat([SBD, notSBD])\n",
    "SBDData = NN(concatRes.drop([\"Class\", \"Prob\"], axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1da5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = SBDData[0].copy()\n",
    "y3 = SBDData[1].copy()\n",
    "z3 = SBDData[2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c513ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBatch(z1, z, \"Weighted HTP F1 Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c240b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBatch(z2, z, \"Weighted Save F1 Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e981b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBatch(z3, z, \"SBD F1 Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05eb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343acbe7",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42152391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varImp(t, df):\n",
    "    varNames = df.columns.tolist()\n",
    "    \n",
    "    imp = t.feature_importances_\n",
    "    impDict = {}\n",
    "    \n",
    "    for feature, importance in zip(varNames, imp):\n",
    "        impDict[feature] = importance\n",
    "    \n",
    "    impDF = pd.DataFrame.from_dict(impDict, orient='index', columns=['Importance'])\n",
    "    \n",
    "    return impDF\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree(x, y, xtest, ytest):\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 2)\n",
    "    \n",
    "    dtc.fit(x,y)\n",
    "    rfc.fit(x,y)\n",
    "    gbc.fit(x,y)\n",
    "    \n",
    "    print(\"--------------------Regular Tree--------------------\")\n",
    "    dtcimp = varImp(dtc, x)\n",
    "    print(dtcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = dtc.predict(x)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    ypred = dtc.predict(xtest)\n",
    "    print(\"Testomg:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "    \n",
    "    print(\"--------------------Random Forest--------------------\")\n",
    "    rfcimp = varImp(rfc, x)\n",
    "    print(rfcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = rfc.predict(x)\n",
    "    ypred = rfc.predict(xtest)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    print(\"Testing:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "    print(\"--------------------Gradient Boost--------------------\")\n",
    "    gbcimp = varImp(gbc, x)\n",
    "    print(gbcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = gbc.predict(x)\n",
    "    ypred = gbc.predict(xtest)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    print(\"Testing:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c642e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(probdf.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1), probdf[\"Churn_Yes\"], xtest, ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(HTP.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis= 1), HTP[\"Churn_Yes\"], HTPTest.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis = 1), HTPTest[\"Churn_Yes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d590177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(SBD.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1), SBD[\"Churn_Yes\"], xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(HTP.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1), HTP[\"Churn_Yes\"], xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(save.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1), save[\"Churn_Yes\"], xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(notHTP.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1), notHTP[\"Churn_Yes\"], notHTPTest.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis = 1), notHTPTest[\"Churn_Yes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba408d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d6c5d1b",
   "metadata": {},
   "source": [
    "# Specialized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc2ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardToPredictTest(std, threshold):\n",
    "    \n",
    "    class0 = class0Test.copy()\n",
    "    class1 = class1Test.copy()\n",
    "    upperlimit = threshold + std\n",
    "    lowerlimit = threshold - std\n",
    "    \n",
    "    print(\"Upperlimit:\", upperlimit, \"Lowerlimit:\", lowerlimit)\n",
    "    \n",
    "    C0HP = class0[(class0[\"Prob\"]>upperlimit)].sort_values(by=\"Prob\", ascending = False)\n",
    "    notC0Hp = class0[(class0[\"Prob\"]<=upperlimit)]\n",
    "\n",
    "    C1LP = class1[(class1[\"Prob\"]<lowerlimit)].sort_values(by=\"Prob\")\n",
    "    notC1LP = class1[(class1[\"Prob\"]>=lowerlimit)]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "        notHTP = pd.DataFrame().append(notC0Hp).append(notC1LP)\n",
    "        HTP = pd.DataFrame()\n",
    "        \n",
    "        alternate = min(len(C0HP), len(C1LP))\n",
    "        for i in range (0, alternate):\n",
    "            HTP = HTP.append(C0HP.iloc[i]).append(C1LP.iloc[i])\n",
    "            #print(len(orderedHTP))\n",
    "\n",
    "        if (alternate == len(C0HP)):\n",
    "            HTP = HTP.append(C1LP.iloc[(len(C0HP)):(len(C1LP))])\n",
    "\n",
    "        else:\n",
    "            HTP = HTP.append(C0HP.iloc[(len(C1LP)):(len(C0HP))])\n",
    "    \n",
    "    print(\"HTP:\", len(HTP))\n",
    "    print(\"notHTP:\", len(notHTP))\n",
    "    \n",
    "    return (HTP, notHTP)\n",
    "\n",
    "def NN(df, xtest, ytest, t2=False, bo = False):\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "\n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    print(\"Starting Model Training\")\n",
    "    history = model.fit(xtrain, ytrain, epochs=200, batch_size=32, shuffle=True, verbose=0)\n",
    "    print(\"Model Training Finished\")\n",
    "    \n",
    "    if (bo):\n",
    "        yprob = model.predict(t2.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis = 1))\n",
    "        print(\"NN\", yprob[0], \"acutal\", t2[\"Churn_Yes\"].head(1))\n",
    "        # Create a scatter plot\n",
    "        plt.scatter(yprob, t2.index, c=t2[\"Churn_Yes\"], cmap='viridis')\n",
    "        plt.xlabel('Predicted Probability')\n",
    "        plt.ylabel('Sample Unit')\n",
    "        plt.title('Predicted Probabilities and Class Labels')\n",
    "        plt.show()\n",
    "        \n",
    "    print(\"Training ROC:\")\n",
    "    pred = model.predict(xtrain)\n",
    "    \n",
    "    #print(pred)\n",
    "    plotROC(pred, ytrain)\n",
    "    #plotNN(history)\n",
    "    return(evalNN(model, xtest, ytest))\n",
    "\n",
    "def evaluate(acc, pred):\n",
    "    cm = confusion_matrix(acc, pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    truePositive = cm[1, 1]\n",
    "    trueNegative = cm[0, 0]\n",
    "    falsePositive = cm[0, 1]\n",
    "    falseNegative = cm[1, 0]\n",
    "    print(\"\\nTrue Positive:\", truePositive)\n",
    "    print(\"True Negative:\", trueNegative)\n",
    "    print(\"False Positive:\", falsePositive)\n",
    "    print(\"False Negative:\", falseNegative)\n",
    "    \n",
    "    accuracy = accuracy_score(acc, pred)\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    tpr = recall_score(acc, pred)\n",
    "    print(\"True-Positve Rate:\", tpr)\n",
    "    f1 = f1_score(acc, pred)\n",
    "    print(\"F1 score:\", f1)\n",
    "    \n",
    "    return cm\n",
    "\n",
    "def evaluateCM(cm):\n",
    "    print(\"\\nTotal Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    tp = cm[1, 1]\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"True-Positve Rate:\", recall)\n",
    "    print(\"F1 score:\", f1)\n",
    "\n",
    "def evalNN(model, xtest, ytest):\n",
    "    pred = model.predict(xtest)\n",
    "    # Plot the histogram\n",
    "    print(\"Test ROC:\")\n",
    "    plotROC(pred, ytest)\n",
    "    bestThresh = thresh(pred, ytest)\n",
    "    classPred = [0 if val < bestThresh else 1 for val in pred]\n",
    "    return(evaluate(ytest, classPred))\n",
    "\n",
    "def NN2(df, df2, test, test2):\n",
    "    \n",
    "    df = df.drop([\"Class\", \"Prob\"], axis =1)\n",
    "    len(df)\n",
    "    xt = test.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    len(xt)\n",
    "    yt = test[\"Churn_Yes\"]\n",
    "    len(yt)\n",
    "\n",
    "    NN1CM = NN(df, xt, yt)\n",
    "    \n",
    "    df2 = df2.drop([\"Class\", \"Prob\"], axis =1)\n",
    "    len(df2)\n",
    "    xt2 = test2.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    len(xt)\n",
    "    yt2 = test2[\"Churn_Yes\"]\n",
    "    len(yt)\n",
    "    \n",
    "    NN2CM = NN(df2, xt2, yt2)\n",
    "    \n",
    "    return (evaluateCM(NN1CM+NN2CM))\n",
    "\n",
    "def NNTree(df, df2, test, test2):\n",
    "    \n",
    "    df = df.drop([\"Class\", \"Prob\"], axis =1)\n",
    "    xt = test.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    yt = test[\"Churn_Yes\"]\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 2)\n",
    "    gbc.fit(df.drop([\"Churn_Yes\"], axis=1),df[\"Churn_Yes\"])\n",
    "    ypred = gbc.predict(xt)\n",
    "    NN1CM = evaluate(yt, ypred)\n",
    "    \n",
    "    df2 = df2.drop([\"Class\", \"Prob\"], axis =1)\n",
    "    len(df2)\n",
    "    xt2 = test2.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    len(xt)\n",
    "    yt2 = test2[\"Churn_Yes\"]\n",
    "    len(yt)\n",
    "    \n",
    "    predict = pd.concat([test, test2])\n",
    "    yprob = gbc.predict_proba(predict.drop([\"Churn_Yes\", \"Class\", \"Prob\"], axis = 1))\n",
    "    print(\"tree\", yprob[:, 1][0], \"acutal\", predict[\"Churn_Yes\"].head(1))\n",
    "    # Create a scatter plot\n",
    "    plt.scatter(yprob[:, 1], predict.index, c=predict[\"Churn_Yes\"], cmap='viridis')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Sample Unit')\n",
    "    plt.title('Predicted Probabilities and Class Labels')\n",
    "    plt.show()\n",
    "    \n",
    "    NN2CM = NN(df2, xt2, yt2, predict, True)\n",
    "    \n",
    "    return (evaluateCM(NN1CM+NN2CM))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f37ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Training \n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "\n",
    "#Getting probabilities\n",
    "yprob = model.predict_proba(xtest)\n",
    "thresholdTest = thresh(yprob[:, 1], ytest)\n",
    "#threshold = 0.5\n",
    "ypred = (yprob[:, 1] > thresholdTest).astype(int)\n",
    "#Log results\n",
    "evaluate(ytest,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ef982",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xtest.copy()\n",
    "test[\"Churn_Yes\"] = ytest\n",
    "test[\"Prob\"] = yprob[:, 1]\n",
    "test[\"Class\"] = ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25492a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestTest(num):\n",
    "    i = (notSBDTest['Prob'] - num).abs().idxmin()\n",
    "    row = notSBDTest.loc[i]\n",
    "    notSBDTest.drop(i, inplace=True)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b454ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1Test = test[test[\"Churn_Yes\"] == 1].sort_values(by=\"Prob\")\n",
    "class0Test = test[test[\"Churn_Yes\"] == 0].sort_values(by=\"Prob\")\n",
    "\n",
    "#Similar but different\n",
    "SBDTest = pd.DataFrame()\n",
    "notSBDTest = class0Test.copy()\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for i in range(len(class1Test)):\n",
    "        #print(len(SBD))\n",
    "        row = class1Test.iloc[i]\n",
    "        SBDTest = SBDTest.append(row)\n",
    "        row2 = findClosestTest(row[\"Prob\"])\n",
    "        SBDTest = SBDTest.append(row2)\n",
    "\n",
    "print(len(SBDTest))\n",
    "print(len(notSBDTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db538f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdProbTest = .5 * test[\"Prob\"].std()\n",
    "\n",
    "fullHTPTest = hardToPredictTest(stdProbTest, thresholdTest)\n",
    "\n",
    "notHTPTest = fullHTPTest[1]\n",
    "HTPTest = fullHTPTest[0]\n",
    "\n",
    "print(\"HTPTest:\", len(HTPTest))\n",
    "print(\"notHTPTest:\", len(notHTPTest))\n",
    "\n",
    "HTPTest[[\"Churn_Yes\", \"Prob\", \"Class\"]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d30c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "upperlimitTest = thresholdTest + stdProbTest\n",
    "lowerlimitTest = thresholdTest - stdProbTest\n",
    "\n",
    "saveTest = test[test['Prob'].between(lowerlimitTest, upperlimitTest)]\n",
    "\n",
    "notsaveTest = test.copy()\n",
    "notsaveTest = notsaveTest.drop(saveTest.index)\n",
    "\n",
    "print(len(saveTest))\n",
    "print(len(notsaveTest))\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2715a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN2(probdf, probdf, test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa094f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NN2(save, notsave, saveTest, notsaveTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78ec6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NN2(HTP, notHTP, test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb07bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNTree(HTP, notHTP, HTPTest, notHTPTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af21028",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTPDF = HTP.copy()\n",
    "HTPDF[\"HTP\"] = 1\n",
    "notHTPDF = notHTP.copy()\n",
    "notHTPDF[\"HTP\"] = 0\n",
    "HTP2 = pd.concat([HTPDF, notHTPDF])\n",
    "\n",
    "HTPDF = HTPTest.copy()\n",
    "HTPDF[\"HTP\"] = 1\n",
    "notHTPDF = notHTPTest.copy()\n",
    "notHTPDF[\"HTP\"] = 0\n",
    "HTP3 = pd.concat([HTPDF, notHTPDF])\n",
    "HTP3\n",
    "\n",
    "xtrainHTP = HTP2.drop([\"Churn_Yes\", \"Prob\", \"Class\", \"HTP\"], axis = 1)\n",
    "ytrainHTP = HTP2[\"HTP\"]\n",
    "\n",
    "xtestHTP = HTP3.drop([\"Churn_Yes\", \"Prob\", \"Class\", \"HTP\"], axis = 1)\n",
    "ytestHTP = HTP3[\"HTP\"]\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 8)\n",
    "gbc.fit(xtrainHTP,ytrainHTP)\n",
    "ypred = gbc.predict(xtestHTP)\n",
    "\n",
    "HTP3[\"Model\"] = ypred\n",
    "\n",
    "HTPTestNN = HTP3[HTP3[\"Model\"] == 1].drop([\"Model\", \"HTP\"], axis = 1)\n",
    "\n",
    "notHTPTestNN = HTP3[HTP3[\"Model\"] == 0].drop([\"Model\", \"HTP\"], axis = 1)\n",
    "\n",
    "NNTree(HTP, notHTP, HTPTestNN, notHTPTestNN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce611b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef696f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf2bdcf",
   "metadata": {},
   "source": [
    "# Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a2efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNTree(df, df2, test, test2):\n",
    "    \n",
    "    tot = pd.concat([df, df2])\n",
    "    \n",
    "    xTrainTot = tot.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    yTrainTot = tot[\"Churn_Yes\"]\n",
    "    \n",
    "    xtrain = df.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    xtrain2 = df2.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    ytrain2 = df2[\"Churn_Yes\"]\n",
    "    \n",
    "    xt = test.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    yt = test[\"Churn_Yes\"]\n",
    "    \n",
    "    xt2 = test2.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    yt2 = test2[\"Churn_Yes\"]\n",
    "    \n",
    "    totTest = pd.concat([test, test2])\n",
    "    \n",
    "    xtest = totTest.drop([\"Class\", \"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    ytest = totTest[\"Churn_Yes\"]\n",
    "\n",
    "    #######################################################################################################\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 2)\n",
    "    gbc.fit(xtrain, ytrain)\n",
    "    \n",
    "    tPred = gbc.predict_proba(xTrainTot)[:, 0]\n",
    "    \n",
    "    #######################################################################################################\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    history = model.fit(xtrain2, ytrain2, epochs=200, batch_size=32, shuffle=True, verbose=0)\n",
    "    \n",
    "    nPred = model.predict(xTrainTot)[:, 0]\n",
    "\n",
    "    bestThresh = bestWeight(tPred, nPred, yTrainTot)\n",
    "    \n",
    "    evalNN(bestThresh[1], bestThresh[0], yTrainTot)\n",
    "    \n",
    "    testPred = (bestThresh[2] * gbc.predict_proba(xtest)[:, 0]) + (bestThresh[3] * model.predict(xtest)[:, 0])\n",
    "    \n",
    "    evalNN(bestThresh[1], testPred, ytest)\n",
    "    \n",
    "def evalNN(thresh, pred, ytest):\n",
    "    plotROC(pred, ytest)\n",
    "    classPred = [0 if val < thresh else 1 for val in pred]\n",
    "    evaluate(ytest, classPred, thresh)\n",
    "    \n",
    "def evaluate(acc, pred, bestthresh):\n",
    "    cm = confusion_matrix(acc, pred)\n",
    "    bestacc = accuracy_score(acc, pred)\n",
    "    besttp = recall_score(acc, pred)\n",
    "    bestf1 = f1_score(acc, pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Best Threshold:\", bestthresh)\n",
    "    print(\"Accuracy:\", bestacc)\n",
    "    print(\"Recall:\", besttp)\n",
    "    print(\"F1:\", bestf1)\n",
    "    \n",
    "    \n",
    "def bestWeight(pred1, pred2, acc):\n",
    "    w1 = 0\n",
    "    w2 = 1\n",
    "    f1 = 0\n",
    "    t = 0\n",
    "    p = 0\n",
    "    \n",
    "    for i in range(101):\n",
    "        weight1 = i/100\n",
    "        weight2 = 1-weight1\n",
    "        \n",
    "        pred = (pred1*weight1) + (pred2*weight2)\n",
    "        test = thresh2(pred, acc)\n",
    "        #print(\"Weight1:\", weight1, \"Weight2:\", weight2, \"Threshold:\", test[1], \"F1:\", test[0])\n",
    "        \n",
    "        if (test[0] > f1):\n",
    "            p = pred\n",
    "            f1 = test[0]\n",
    "            w1 = weight1\n",
    "            w2 = weight2\n",
    "            t = test[1]\n",
    "            \n",
    "    print(\"Best Weight1:\", w1)\n",
    "    print(\"Best Weight2:\", w2)\n",
    "    print(\"Best F1:\", f1)\n",
    "    print(\"Best Threshold:\", t)\n",
    "    \n",
    "    return([p, t, w1, w2])\n",
    "\n",
    "def thresh2(pred, ytest):\n",
    "    bestf1 = 0\n",
    "    bestthresh = 0\n",
    "\n",
    "    for i in range(1,100):\n",
    "        classPred = [0 if val < (i/100) else 1 for val in pred]\n",
    "        f1 = f1_score(ytest, classPred)\n",
    "        if (f1>bestf1):\n",
    "            bestf1 = f1\n",
    "            bestthresh=(i/100)\n",
    "\n",
    "    return (bestf1, bestthresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13673cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222b436",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNTree(HTP, notHTP, HTPTest, notHTPTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab825589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4f8c54a",
   "metadata": {},
   "source": [
    "# HTP NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00996d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTPDF = HTP.copy()\n",
    "HTPDF[\"HTP\"] = 1\n",
    "notHTPDF = notHTP.copy()\n",
    "notHTPDF[\"HTP\"] = 0\n",
    "HTP2 = pd.concat([HTPDF, notHTPDF])\n",
    "HTP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51baad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTPDF = HTPTest.copy()\n",
    "HTPDF[\"HTP\"] = 1\n",
    "notHTPDF = notHTPTest.copy()\n",
    "notHTPDF[\"HTP\"] = 0\n",
    "HTP3 = pd.concat([HTPDF, notHTPDF])\n",
    "HTP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d55351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree(x, y, xtest, ytest):\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 2)\n",
    "    \n",
    "    dtc.fit(x,y)\n",
    "    rfc.fit(x,y)\n",
    "    gbc.fit(x,y)\n",
    "    \n",
    "    print(\"--------------------Regular Tree--------------------\")\n",
    "    dtcimp = varImp(dtc, x)\n",
    "    print(dtcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = dtc.predict(x)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    ypred = dtc.predict(xtest)\n",
    "    print(\"Testomg:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "    \n",
    "    print(\"--------------------Random Forest--------------------\")\n",
    "    rfcimp = varImp(rfc, x)\n",
    "    print(rfcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = rfc.predict(x)\n",
    "    ypred = rfc.predict(xtest)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    print(\"Testing:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "    print(\"--------------------Gradient Boost--------------------\")\n",
    "    gbcimp = varImp(gbc, x)\n",
    "    print(gbcimp.sort_values(\"Importance\", ascending= False).head(5))\n",
    "    yfit = gbc.predict(x)\n",
    "    ypred = gbc.predict(xtest)\n",
    "    print(\"Training:\")\n",
    "    evaluate(y, yfit)\n",
    "    print(\"Testing:\")\n",
    "    evaluate(ytest, ypred)\n",
    "    \n",
    "def evaluate(acc, pred):\n",
    "    cm = confusion_matrix(acc, pred)\n",
    "    bestacc = accuracy_score(acc, pred)\n",
    "    besttp = recall_score(acc, pred)\n",
    "    bestf1 = f1_score(acc, pred)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Accuracy:\", bestacc)\n",
    "    print(\"Recall:\", besttp)\n",
    "    print(\"F1:\", bestf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc08506",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainHTP = HTP2.drop([\"Churn_Yes\", \"Prob\", \"Class\", \"HTP\"], axis = 1)\n",
    "ytrainHTP = HTP2[\"HTP\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aceeff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ed284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f001cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c5d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8529c18",
   "metadata": {},
   "source": [
    "# Recompile NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def NN(df, xtest, ytest):\n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=30))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "\n",
    "    history = model.fit(xtrain, ytrain, epochs=1, batch_size=32, shuffle=False, \n",
    "                        validation_data=val_data, verbose=0)\n",
    "    \n",
    "    pred = model.predict(xtest)\n",
    "\n",
    "    return(thresh(pred,ytest))\n",
    "\n",
    "def thresh(pred, ytest):\n",
    "    bestf1 = 0\n",
    "    bestthresh = 0\n",
    "\n",
    "    for i in range(1,100):\n",
    "        classPred = [0 if val < (i/100) else 1 for val in pred]\n",
    "        f1 = f1_score(ytest, classPred)\n",
    "        if (f1>bestf1):\n",
    "            bestf1 = f1\n",
    "            bestthresh=(i/100)\n",
    "\n",
    "    return bestf1\n",
    "\n",
    "def plotline(x, y, xlab, ylab):\n",
    "    # Plot the recall values\n",
    "    plt.plot(x, y, 'k', label=ylab)\n",
    "\n",
    "    plt.title((ylab + \" Line Graph\"))\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1recompile = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b07c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    f1recompile.append(NN(probdf.drop([\"Prob\", \"Class\"], axis=1), xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab8839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(list(range(200)), f1recompile, \"Epoch\", \"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=30))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy', recall_m, precision_m, f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc199a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(df, xtest, ytest):\n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    val_data = (xtest, ytest)\n",
    "\n",
    "    history = model.fit(xtrain, ytrain, epochs=1, batch_size=32, shuffle=False, \n",
    "                        validation_data=val_data, verbose=0)\n",
    "    \n",
    "    pred = model.predict(xtest)\n",
    "\n",
    "    return(thresh(pred,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1same = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc405a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    f1same.append(NN(probdf.drop([\"Prob\", \"Class\"], axis=1), xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a33a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotline(list(range(200)), f1same, \"Epoch\", \"F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991df513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca9e6a0",
   "metadata": {},
   "source": [
    "# New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d196f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\21sla\\OneDrive - Dickinson College\\Data300\\churn-bigml-80.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r\"C:\\Users\\21sla\\OneDrive - Dickinson College\\Data300\\churn-bigml-20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fe468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/mnassrib/telecom-churn-datasets?select=churn-bigml-80.csv\n",
    "#https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers\n",
    "\n",
    "churn = pd.concat([train, test])\n",
    "\n",
    "len(churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38860246",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop State\n",
    "clean = churn.drop(\"State\", axis=1)\n",
    "clean[\"Churn\"] = clean[\"Churn\"].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859cb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardToPredictTest(class0, class1, std, threshold):\n",
    "    \n",
    "    upperlimit = threshold + std\n",
    "    lowerlimit = threshold - std\n",
    "    \n",
    "    print(\"Upperlimit:\", upperlimit, \"Lowerlimit:\", lowerlimit)\n",
    "    \n",
    "    C0HP = class0[(class0[\"Prob\"]>upperlimit)].sort_values(by=\"Prob\", ascending = False)\n",
    "    notC0Hp = class0[(class0[\"Prob\"]<=upperlimit)]\n",
    "\n",
    "    C1LP = class1[(class1[\"Prob\"]<lowerlimit)].sort_values(by=\"Prob\")\n",
    "    notC1LP = class1[(class1[\"Prob\"]>=lowerlimit)]\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "        notHTP = pd.DataFrame().append(notC0Hp).append(notC1LP)\n",
    "        HTP = pd.DataFrame()\n",
    "        \n",
    "        alternate = min(len(C0HP), len(C1LP))\n",
    "        for i in range (0, alternate):\n",
    "            HTP = HTP.append(C0HP.iloc[i]).append(C1LP.iloc[i])\n",
    "            #print(len(orderedHTP))\n",
    "\n",
    "        if (alternate == len(C0HP)):\n",
    "            HTP = HTP.append(C1LP.iloc[(len(C0HP)):(len(C1LP))])\n",
    "\n",
    "        else:\n",
    "            HTP = HTP.append(C0HP.iloc[(len(C1LP)):(len(C0HP))])\n",
    "    \n",
    "    print(\"HTP:\", len(HTP))\n",
    "    print(\"notHTP:\", len(notHTP))\n",
    "    \n",
    "    return (HTP, notHTP)\n",
    "\n",
    "def NNTree(df, df2, test, test2):\n",
    "    \n",
    "    df = df.drop([\"Prob\"], axis =1)\n",
    "    xt = test.drop([\"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    yt = test[\"Churn_Yes\"]\n",
    "\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42, max_depth = 2)\n",
    "    gbc.fit(df.drop([\"Churn_Yes\"], axis=1),df[\"Churn_Yes\"])\n",
    "    ypred = gbc.predict(xt)\n",
    "    NN1CM = evaluate(yt, ypred)\n",
    "    \n",
    "    df2 = df2.drop([\"Prob\"], axis =1)\n",
    "    len(df2)\n",
    "    xt2 = test2.drop([\"Prob\", \"Churn_Yes\"], axis=1)\n",
    "    len(xt)\n",
    "    yt2 = test2[\"Churn_Yes\"]\n",
    "    len(yt)\n",
    "    \n",
    "    yprob = gbc.predict_proba(xt2)\n",
    "    # Create a scatter plot\n",
    "    plt.scatter(yprob[:, 1], test2.index, c=test2[\"Churn_Yes\"], cmap='viridis')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Sample Unit')\n",
    "    plt.title('Predicted Probabilities and Class Labels')\n",
    "    plt.show()\n",
    "    \n",
    "    NN2CM = NN(df2, xt2, yt2)\n",
    "    \n",
    "    return (evaluateCM(NN1CM+NN2CM))\n",
    "\n",
    "def NN(df, xtest, ytest):\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=18))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "\n",
    "    \n",
    "    xtrain = df.drop(\"Churn_Yes\", axis=1)\n",
    "    ytrain = df[\"Churn_Yes\"]\n",
    "    \n",
    "    print(\"Starting Model Training\")\n",
    "    history = model.fit(xtrain, ytrain, epochs=200, batch_size=32, shuffle=True, verbose=0)\n",
    "    print(\"Model Training Finished\")\n",
    "    \n",
    "    print(\"Training ROC:\")\n",
    "    pred = model.predict(xtrain)\n",
    "    \n",
    "    #print(pred)\n",
    "    plotROC(pred, ytrain)\n",
    "    #plotNN(history)\n",
    "    return(evalNN(model, xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ce89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9dedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dummies\n",
    "dummies = pd.get_dummies(clean, drop_first= True)\n",
    "clean = dummies\n",
    "clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf50d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean.drop('Churn_True', axis=1)\n",
    "y = clean['Churn_True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d75ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d87d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting probabilities\n",
    "yprob = model.predict_proba(xtest)\n",
    "threshold = thresh(yprob[:, 1], ytest)\n",
    "#threshold = 0.5\n",
    "ypred = (yprob[:, 1] > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log results\n",
    "evaluate(ytest,ypred, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1825f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xtrain.copy()\n",
    "train[\"Churn_Yes\"] = ytrain\n",
    "\n",
    "test = xtest.copy()\n",
    "test[\"Churn_Yes\"] = ytest\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "trainprob = model.predict_proba(xtrain)[:, 1]\n",
    "testprob = model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "train[\"Prob\"] = trainprob\n",
    "test[\"Prob\"] = testprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a683bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42777561",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainClass0 = train[train[\"Churn_Yes\"] == 0]\n",
    "trainClass1 = train[train[\"Churn_Yes\"] == 1]\n",
    "\n",
    "testClass0 = test[test[\"Churn_Yes\"] == 0]\n",
    "testClass1 = test[test[\"Churn_Yes\"] == 1]\n",
    "\n",
    "std = .5* train[\"Prob\"].std()\n",
    "\n",
    "\n",
    "trainHTP = hardToPredictTest(trainClass0, trainClass1, std, threshold)\n",
    "testHTP = hardToPredictTest(testClass0, testClass1, std, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae225b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNTree(trainHTP[0], trainHTP[1], testHTP[0], testHTP[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN(train.drop(\"Prob\", axis=1), xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17b648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
